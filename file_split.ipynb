{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "#os.environ[\"SPARK_HOME\"] = f\"/content/{ver_spark}-bin-hadoop2.7\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Colab\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'UAI.txt'\n",
    "df_spark = spark.read.csv(archivo, inferSchema=True, header=False)\n",
    "df_spark = df_spark.withColumnRenamed(\"_c0\", \"raw_data\")\n",
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = df_spark.withColumn('IDC', F.substring('raw_data',1,9))\\\n",
    "            .withColumn('CODMES_UN', F.substring('raw_data',10,6))\\\n",
    "            .withColumn(\"UN\",F.expr(\"substring(raw_data, 16, length(raw_data)-15)\"))\n",
    "\n",
    "df = df.drop('raw_data')\n",
    "df.show()\n",
    "\n",
    "#saving as parquet \n",
    "#df.write.parquet(\"output/proto.parquet\")b"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82e838a5afa22f1da4d2e3c46086c8bf0ba22a28e03b505433d7913719038186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
